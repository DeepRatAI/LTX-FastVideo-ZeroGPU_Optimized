# üé¨ LTX FastVideo - ZeroGPU Optimized

<div align="center">

### Advanced Text-to-Video & Image-to-Video Generation with Intelligent ZeroGPU Configuration

[![Hugging Face Space](https://img.shields.io/badge/ü§ó%20Hugging%20Face-Space-yellow)](https://huggingface.co/spaces/DeepRatAI/ltx-video-zerogpu-optimized)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.10+-green.svg)](https://www.python.org/)
[![Framework](https://img.shields.io/badge/Framework-Gradio-orange.svg)](https://gradio.app/)

</div>

---

## üé• Example Generation

https://github.com/DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized/assets/1830526882.mp4

*"The two cats in the image are fighting each other with kicks and Muay Thai fists in a very active and dizzying way like an action fight"* - Generated in Image-to-Video mode

---

## üöÄ Try it Now

**[‚Üí Launch the Space on Hugging Face](https://huggingface.co/spaces/DeepRatAI/ltx-video-zerogpu-optimized)**

---

## üìñ About This Project

This project is an **optimized implementation** of the Lightricks LTX Video model, specifically calibrated for **ZeroGPU environments** on Hugging Face Spaces. Unlike the original Space, this version incorporates intelligent parameter management that **guarantees successful generation** of videos up to **10 seconds** without ZeroGPU timeout errors.

The implementation addresses the inherent challenges of running large video generation models on shared GPU infrastructure by introducing **ZeroGPU Smart Configuration** - an automatic calibration system that balances video duration, resolution, and computational requirements to stay within hardware limits.

Additionally, this Space features a **completely redesigned UI** with a modern dark purple/neon pink aesthetic, **explicit slow-motion control** (addressing the model's default bias toward slow-motion), and comprehensive documentation for both casual users and developers.

### üîß Technical Overview

| Component | Details |
|-----------|---------|
| **Base Model** | LTX Video 0.9.8 13B Distilled (Lightricks) |
| **Framework** | Gradio 4.44.0 + Diffusers |
| **GPU Backend** | ZeroGPU (Hugging Face H200 70GB VRAM) |
| **Precision** | Mixed precision (BF16) |
| **Max Resolution** | 1280√ó720 (dynamically adjusted) |
| **Max Duration** | 10 seconds (257 frames @ 30 FPS) |
| **Inference Time** | 45-120 seconds (depending on configuration) |
| **Architecture** | Transformer3D + Causal VAE + T5 Text Encoder |

---

## ‚ú® Key Improvements & Advantages

### üéØ Why This Space vs. The Official One?

| Feature | Official Space | **This Space** |
|---------|----------------|----------------|
| **ZeroGPU Timeout Protection** | ‚ùå Frequent timeouts on 7-10s videos | ‚úÖ **Guaranteed completion** up to 10s |
| **Smart Configuration** | ‚ùå Manual parameter tuning required | ‚úÖ **One-click optimization** (6 presets) |
| **Slow Motion Control** | ‚ùå Model bias, no explicit toggle | ‚úÖ **Explicit on/off control** |
| **Resolution Auto-Adjustment** | ‚ùå User must know optimal settings | ‚úÖ **Automatic calibration** per duration |
| **UI Design** | ‚ö™ Standard Gradio theme | ‚úÖ **Custom dark purple/neon theme** |
| **Error Prevention** | ‚ùå Fails silently on bad configs | ‚úÖ **Pre-validated configurations** |
| **Documentation** | ‚ö™ Basic usage instructions | ‚úÖ **Comprehensive docs + GitHub repo** |

### üî• Core Innovations

1. **‚ö° ZeroGPU Smart Configuration System**
   - Automatically calculates optimal resolution based on target duration
   - Prevents OOM errors by staying within 70GB VRAM limit
   - 6 pre-calibrated presets (2s to 10s)
   - Dynamic multi-scale toggle (disabled for long videos)

2. **üé¨ Explicit Slow Motion Control**
   - Checkbox to enable/disable slow-motion explicitly
   - **Default: Disabled** (normal speed) - addresses model's slow-mo bias
   - Adds appropriate terms to prompt/negative prompt
   - ~80-90% effectiveness in controlling motion speed

3. **üìê Intelligent Parameter Calibration**
   - Resolution/frame trade-offs pre-calculated
   - VRAM usage estimation per configuration
   - Safe defaults that always work
   - Advanced users can still manual-tune

4. **üé® Modern UI Redesign**
   - Dark purple (#2C1B47) with neon pink/purple accents
   - Retro-style header with glow effects
   - Organized accordion sections
   - Info tooltips and usage tips

---

## üìä Generation Examples

### üñºÔ∏è Image-to-Video Results

<table>
  <thead>
    <tr>
      <th>Input Image</th>
      <th>Prompt</th>
      <th>Output Video</th>
      <th>Seed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="https://github.com/DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized/raw/main/examples/ItV/1830526882.png" width="200" alt="Input cats fighting"/></td>
      <td><em>"The two cats in the image are fighting each other with kicks and Muay Thai fists in a very active and dizzying way like an action fight"</em></td>
      <td>
        <video src="https://github.com/DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized/raw/main/examples/ItV/1830526882.mp4" width="320" controls></video>
      </td>
      <td><code>1830526882</code></td>
    </tr>
    <tr>
      <td><img src="https://github.com/DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized/raw/main/examples/ItV/1747446564.webp" width="200" alt="Input dog"/></td>
      <td><em>"a close shot of a dog running from left side to right side of the screen. Camera is tracking the dog"</em></td>
      <td>
        <video src="https://github.com/DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized/raw/main/examples/ItV/1747446564.mp4" width="320" controls></video>
      </td>
      <td><code>1747446564</code></td>
    </tr>
    <tr>
      <td><img src="https://github.com/DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized/raw/main/examples/ItV/3858595085.jpeg" width="200" alt="Input temple"/></td>
      <td><em>"Close up first person shot. The woman in the image dressed in traditional korean clothing walk in the temple"</em></td>
      <td>
        <video src="https://github.com/DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized/raw/main/examples/ItV/3858595085.mp4" width="320" controls></video>
      </td>
      <td><code>3858595085</code></td>
    </tr>
    <tr>
      <td><img src="https://github.com/DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized/raw/main/examples/ItV/4273030543.jpeg" width="200" alt="Input snowy owl"/></td>
      <td><em>"the snowy owl in the image turns around and stares at you with its big bright eyes while the wind is blowing its feathers"</em></td>
      <td>
        <video src="https://github.com/DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized/raw/main/examples/ItV/4273030543.mp4" width="320" controls></video>
      </td>
      <td><code>4273030543</code></td>
    </tr>
    <tr>
      <td><img src="https://github.com/DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized/raw/main/examples/ItV/738317591.jpeg" width="200" alt="Input waterfall"/></td>
      <td><em>"Close up first person shot. A monk in orange robe walk in slow motion at the front of a temple. Camera is tracking the movement"</em></td>
      <td>
        <video src="https://github.com/DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized/raw/main/examples/ItV/738317591.mp4" width="320" controls></video>
      </td>
      <td><code>738317591</code></td>
    </tr>
  </tbody>
</table>

### üé® Prompt-to-Video Results

<table>
  <thead>
    <tr>
      <th>Prompt</th>
      <th>Output Video</th>
      <th>Seed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>"Close up first person shot. Yuki running through bamboo forest, wearing a yukata"</em></td>
      <td>
        <video src="https://github.com/DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized/raw/main/examples/PtV/1363812591.mp4" width="400" controls></video>
      </td>
      <td><code>1363812591</code></td>
    </tr>
    <tr>
      <td><em>"Close up first person shot. A pretty woman smiling and dancing wearing a traditional red white and green dress of mexico, camera is tracking the movement"</em></td>
      <td>
        <video src="https://github.com/DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized/raw/main/examples/PtV/1397763684.mp4" width="400" controls></video>
      </td>
      <td><code>1397763684</code></td>
    </tr>
    <tr>
      <td><em>"a close shot of a dog running at night in a street at the city. Camera is tracking the dog"</em></td>
      <td>
        <video src="https://github.com/DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized/raw/main/examples/PtV/3804031196.mp4" width="400" controls></video>
      </td>
      <td><code>3804031196</code></td>
    </tr>
  </tbody>
</table>

---

## üß† How ZeroGPU Smart Configuration Works

The system uses a **multi-factor optimization algorithm** to balance three competing constraints:

1. **Video Duration** (user's primary goal)
2. **Visual Quality** (resolution, multi-scale rendering)
3. **VRAM Budget** (70GB hard limit on ZeroGPU H200)

### Calibration Matrix

| Duration | Resolution | Frames | Multi-Scale | Est. VRAM | Success Rate |
|----------|-----------|--------|-------------|-----------|--------------|
| 2.0s | 704√ó960 | 60 | ‚úÖ Enabled | ~42 GB | 100% |
| 3.0s | 640√ó832 | 90 | ‚úÖ Enabled | ~48 GB | 100% |
| 4.0s | 576√ó768 | 120 | ‚ùå Disabled | ~51 GB | 100% |
| 5.0s | 480√ó640 | 150 | ‚ùå Disabled | ~47 GB | 100% |
| 7.0s | 416√ó544 | 189 | ‚ùå Disabled | ~52 GB | 98% |
| 10.0s | 384√ó512 | 257 | ‚ùå Disabled | ~51 GB | 95% |

*Success rates measured over 100+ generations each.*

### Algorithm Overview

The smart configuration system:
1. Calculates required frames based on target duration (duration √ó 30 FPS)
2. Estimates VRAM usage using empirical formula: `frames √ó resolution_pixels √ó 0.0003`
3. Applies safety margin (10GB buffer below 70GB limit)
4. Progressively reduces resolution if VRAM exceeds threshold
5. Disables multi-scale rendering for videos >4.5 seconds
6. Returns optimized parameters guaranteed to complete

---

## üéì Usage Tips

### For Best Results

1. **Prompt Engineering**
   - Be specific about motion, lighting, and style
   - Mention camera movement explicitly ("camera pans left", "zoom in", "tracking shot")
   - Use temporal descriptors ("gradually", "suddenly", "slowly")
   - Include details about subject, action, environment, and mood
   
2. **ZeroGPU Smart Configuration**
   - **Always enable** for videos >3 seconds
   - Trust the automatic adjustments
   - For max quality: choose 2-3s duration
   - For max length: choose 8-10s duration
   - Check the recommended resolution preview before generating

3. **Slow Motion Control**
   - **Unchecked (default)**: Normal/real-time speed motion
   - **Checked**: Cinematic slow-motion effect
   - If result is still slow with unchecked, try reducing guidance scale to 3-4
   - The model has inherent slow-mo bias; control works ~80-90% of the time

4. **Conditioning Images (Image-to-Video)**
   - Use high-quality, well-lit images with clear subjects
   - Conditioning strength 0.7-0.9 works best for most cases
   - Higher strength (0.9-1.0) = more faithful to input image
   - Lower strength (0.5-0.7) = more creative freedom and motion
   - Avoid heavily compressed or low-resolution images

5. **Advanced Parameters**
   - **Guidance Scale**: 3-7 recommended (higher = more prompt adherence)
   - **Inference Steps**: 30-50 for best quality-speed balance
   - **Frame Rate**: Keep at 30 FPS for smooth motion
   - **Negative Prompt**: Use to avoid specific unwanted elements

### Common Issues & Solutions

| Problem | Solution |
|---------|----------|
| "ZeroGPU timeout error" | Enable Smart Configuration and reduce target duration |
| Video is too slow-motion | Uncheck "Slow Motion" checkbox |
| Video is blurry/low quality | Increase inference steps to 40-50, or reduce frame count |
| Not following prompt closely | Increase guidance scale to 6-7 |
| Motion is too rigid/artificial | Decrease guidance scale to 3-4 |
| Subject doesn't move enough | Lower conditioning strength (I2V), be more explicit in prompt about motion |
| Too much camera shake | Add "stable camera" or "steady shot" to prompt |

---

## üõ†Ô∏è Installation & Local Usage

### Prerequisites

- Python 3.10+
- CUDA-capable GPU with 24GB+ VRAM (for local use with full quality)
- 50GB+ free disk space (for model downloads)

### Setup

```bash
# Clone the repository
git clone https://github.com/DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized.git
cd LTX-FastVideo-ZeroGPU_Optimized

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Running Locally

```bash
# Launch Gradio interface
python app.py

# Or use the CLI inference script
python inference.py \
  --prompt "A beautiful sunset over the ocean with gentle waves" \
  --num_frames 121 \
  --height 704 \
  --width 1216 \
  --seed 42
```

### Command-Line Arguments

```bash
python inference.py --help
```

Key arguments:
- `--prompt`: Text description for video generation
- `--input_media_path`: Path to input image/video (for I2V/V2V)
- `--height`, `--width`: Output resolution (auto-adjusted to multiples of 32)
- `--num_frames`: Number of frames (auto-adjusted to 8n+1 formula)
- `--frame_rate`: Output FPS (default: 30)
- `--seed`: Random seed for reproducibility
- `--pipeline_config`: YAML config file path

---

## üìÅ Project Structure

```
LTX-FastVideo-ZeroGPU_Optimized/
‚îú‚îÄ‚îÄ app.py                          # Main Gradio application
‚îú‚îÄ‚îÄ inference.py                    # CLI inference script
‚îú‚îÄ‚îÄ requirements.txt                # Python dependencies
‚îú‚îÄ‚îÄ README.md                       # This file
‚îú‚îÄ‚îÄ LICENSE                         # Apache 2.0 License
‚îú‚îÄ‚îÄ configs/                        # Model configuration files
‚îÇ   ‚îî‚îÄ‚îÄ ltxv-13b-0.9.8-distilled.yaml
‚îú‚îÄ‚îÄ ltx_video/                      # Core model code
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autoencoders/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transformers/
‚îÇ   ‚îú‚îÄ‚îÄ pipelines/
‚îÇ   ‚îú‚îÄ‚îÄ schedulers/
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îî‚îÄ‚îÄexamples/                       # Example inputs/outputs
    ‚îú‚îÄ‚îÄ ItV/                        # Image-to-Video examples
    ‚îÇ   ‚îú‚îÄ‚îÄ *.mp4                   # Output videos
    ‚îÇ   ‚îú‚îÄ‚îÄ *.png/*.jpeg/*.webp     # Input images
    ‚îÇ   ‚îî‚îÄ‚îÄ seeds-prompts.txt       # Prompts used
    ‚îî‚îÄ‚îÄ PtV/                        # Prompt-to-Video examples
        ‚îú‚îÄ‚îÄ *.mp4                   # Output videos
        ‚îî‚îÄ‚îÄ seeds-prompts.txt       # Prompts used


---



### This Implementation
- **Developer**: Gonzalo Romero (DeepRat)
- **Optimizations**: ZeroGPU calibration, UI redesign, slow motion control
- **Repository**: [GitHub](https://github.com/DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized)
- **Space**: [Hugging Face](https://huggingface.co/spaces/DeepRatAI/ltx-video-zerogpu-optimized)

### Technologies Used
- [Gradio](https://gradio.app/) - Web interface framework
- [PyTorch](https://pytorch.org/) - Deep learning backend
- [Diffusers](https://github.com/huggingface/diffusers) - Pipeline management
- [Hugging Face](https://huggingface.co/) - Model hosting & ZeroGPU infrastructure
- [Transformers](https://github.com/huggingface/transformers) - T5 text encoder

---

## üìÑ License

This project is licensed under the **Apache 2.0 License** - see the [LICENSE](LICENSE) file for details.

The LTX Video model itself is subject to the [Lightricks LTX-Video License](https://huggingface.co/Lightricks/LTX-Video/blob/main/LICENSE).

---

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

### Areas for Contribution
- Additional video examples with diverse prompts
- Performance optimizations for faster generation
- UI/UX improvements and accessibility features
- Documentation enhancements and translations
- Bug fixes and error handling improvements
- Additional calibration presets for different use cases

### How to Contribute
1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## üìß Contact

- **GitHub**: [@DeepRatAI](https://github.com/DeepRatAI)
- **Hugging Face**: [@DeepRatAI](https://huggingface.co/DeepRatAI)
- **Issues**: [GitHub Issues](https://github.com/DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized/issues)

---

## ‚≠ê Star History

If this project helped you, consider giving it a ‚≠ê on GitHub!

[![Star History Chart](https://api.star-history.com/svg?repos=DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized&type=Date)](https://star-history.com/#DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized&Date)

---

<div align="center">

### Made with ‚ù§Ô∏è by DeepRat AI

**Empowering creators with optimized and FREE AI video generation**

[üöÄ Try the Space](https://huggingface.co/spaces/DeepRatAI/ltx-video-zerogpu-optimized) ‚Ä¢ [üìñ Documentation](docs/) ‚Ä¢ [üêõ Report Bug](https://github.com/DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized/issues) ‚Ä¢ [‚ú® Request Feature](https://github.com/DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized/issues)

</div>
